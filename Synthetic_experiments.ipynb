{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-t8FU4gW8G9",
        "outputId": "77f9bd0d-14bd-4723-8353-afaadc6e6d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pykeops in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pykeops) (1.22.4)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from pykeops) (2.10.4)\n",
            "Requirement already satisfied: keopscore==2.1.2 in /usr/local/lib/python3.10/dist-packages (from pykeops) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geomloss[full] in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geomloss[full]) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from geomloss[full]) (2.0.1+cu118)\n",
            "Requirement already satisfied: pykeops in /usr/local/lib/python3.10/dist-packages (from geomloss[full]) (2.1.2)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from pykeops->geomloss[full]) (2.10.4)\n",
            "Requirement already satisfied: keopscore==2.1.2 in /usr/local/lib/python3.10/dist-packages (from pykeops->geomloss[full]) (2.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->geomloss[full]) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->geomloss[full]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->geomloss[full]) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->geomloss[full]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->geomloss[full]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->geomloss[full]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->geomloss[full]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->geomloss[full]) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->geomloss[full]) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->geomloss[full]) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pot in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from pot) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from pot) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pykeops\n",
        "!pip install geomloss[full]\n",
        "!pip install pot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "from random import choices\n",
        "import torch\n",
        "\n",
        "import geomloss\n",
        "import pykeops\n",
        "from pykeops.torch import generic_sum\n",
        "import pickle as pkl\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys, os\n",
        "project_path = '/content/drive/MyDrive'\n",
        "sys.path.append(project_path)\n",
        "\n",
        "import warnings\n",
        "\n",
        "import time\n",
        "from synthetic_utils import *\n",
        "from utils_torch import cost_mat\n",
        "\n",
        "import ot\n",
        "\n",
        "from absl import flags, app\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mahd5IlIXxpC",
        "outputId": "1145ba6b-8be0-408c-97b4-1b46f236f5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "yNpsZnvfYH6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in ['imgs', 'generated_samples']:\n",
        "  if not os.path.exists(f'{project_path}/{name}'):\n",
        "    os.makedirs(f'{project_path}/{name}')"
      ],
      "metadata": {
        "id": "9D_jMRvvcPGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tv(x1, x2, n_pts=40):\n",
        "    arr = np.zeros((n_pts+1, n_pts+1))\n",
        "    arr2 = np.zeros((n_pts+1, n_pts+1))\n",
        "\n",
        "    if np.max(np.abs(x1)) >=2:\n",
        "        raise ValueError(\"argument 1 of get_iou has to be in [-1,1] square\")\n",
        "    factor = n_pts / 4\n",
        "    idx = ((x1 + 2)*factor).astype(int)\n",
        "    idx2 = ((np.clip(x2, -2, 2) + 2)*factor).astype(int)\n",
        "    print(idx2.max())\n",
        "\n",
        "    idx, counts = np.unique(idx, return_counts=True, axis = 0)\n",
        "    idx2, counts2 = np.unique(idx2, return_counts=True, axis = 0)\n",
        "\n",
        "\n",
        "    arr[idx[:, 0], idx[:, 1]] = counts / np.sum(counts)\n",
        "    arr2[idx2[:, 0], idx2[:, 1]] = counts2 / np.sum(counts2)\n",
        "\n",
        "    diff = (np.abs(arr - arr2)).sum()/2\n",
        "\n",
        "    return diff"
      ],
      "metadata": {
        "id": "7Z0Usye5-Mfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pykeops.torch import generic_sum\n",
        "transfer = generic_sum(\n",
        "    \"Exp( (F_i + G_j - IntInv(2)*SqDist(X_i,Y_j)) / E ) * L_j\",  # See the formula above\n",
        "    \"Lab = Vi(2)\",  # Output:  one vector of size 3 per line\n",
        "    \"E   = Pm(1)\",  # 1st arg: a scalar parameter, the temperature\n",
        "    \"X_i = Vi(2)\",  # 2nd arg: one 2d-point per line\n",
        "    \"Y_j = Vj(2)\",  # 3rd arg: one 2d-point per column\n",
        "    \"F_i = Vi(1)\",  # 4th arg: one scalar value per line\n",
        "    \"G_j = Vj(1)\",  # 5th arg: one scalar value per column\n",
        "    \"L_j = Vj(2)\",  # 6th arg: one vector of size 3 per column\n",
        ")\n",
        "\n",
        "loss_l1 = generic_sum(\n",
        "    \"Exp( (F_i + G_j - Sum(Abs(X_i - Y_j))) / E ) * Sum(Abs(A_i-Y_j))\",  # See the formula above\n",
        "    \"Lab = Vi(2)\",  # Output:  one vector of size 3 per line\n",
        "    \"E   = Pm(1)\",  # 1st arg: a scalar parameter, the temperature\n",
        "    \"X_i = Vi(2)\",  # 2nd arg: one 2d-point per line\n",
        "    \"Y_j = Vj(2)\",  # 3rd arg: one 2d-point per column\n",
        "    \"F_i = Vi(1)\",  # 4th arg: one scalar value per line\n",
        "    \"G_j = Vj(1)\",  # 5th arg: one scalar value per column\n",
        "    \"A_i = Vi(2)\",  # 6th arg: one vector of size 3 per column\n",
        ")\n",
        "\n",
        "\n",
        "loss_l1_grad = generic_sum(\n",
        "    \"Exp( (F_i + G_j - Sum(Abs(X_i-Y_j))) / E ) * Sign(X_i - Y_j)\",  # See the formula above\n",
        "    \"Lab = Vi(2)\",  # Output:  one vector of size 3 per line\n",
        "    \"E   = Pm(1)\",  # 1st arg: a scalar parameter, the temperature\n",
        "    \"X_i = Vi(2)\",  # 2nd arg: one 2d-point per line\n",
        "    \"Y_j = Vj(2)\",  # 3rd arg: one 2d-point per column\n",
        "    \"F_i = Vi(1)\",  # 4th arg: one scalar value per line\n",
        "    \"G_j = Vj(1)\",  # 5th arg: one scalar value per column\n",
        "    # \"A_i = Vi(2)\",  # 6th arg: one vector of size 3 per column\n",
        ")\n",
        "\n",
        "l1_dist = lambda x, y: torch.clamp_min(torch.sum(torch.abs(\n",
        "    x[:,None,:] - y[None,:,:]), axis=-1), 1e-8)\n",
        "l1_dist_formula = \"Sum(Abs(X-Y))\"\n"
      ],
      "metadata": {
        "id": "qlOdIZaPSxkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = Opt()._asdict()\n",
        "d['exp_id'] = int(str(np.random.normal()).rsplit('.')[1][:16])\n",
        "d['shape_name'] = 'ellipsis'\n",
        "d['N'] = 400000\n",
        "d['eps'] = 5\n",
        "d['cost'] = 'l2'\n",
        "d['n_iter'] = 500#500\n",
        "d['scaling'] = .99#z.9999\n",
        "d['lr'] = 1e-3\n",
        "d['use_bn']=False\n",
        "d['hidden_neurons']=256\n",
        "d['hidden_layers']=2\n",
        "d['activation']='tanh'\n",
        "d['input_scale'] = [2, 2]\n",
        "d['input_mean'] = [-1, -1]\n",
        "d['input_dist'] = 'uniform'\n",
        "display(d)\n",
        "use_emd = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "5_u72nCVZxPa",
        "outputId": "40ac0e57-6702-4e51-f4d5-2dc0ac896340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'exp_id': 8973876331863215,\n",
              " 'shape_name': 'ellipsis',\n",
              " 'N': 400000,\n",
              " 'eps': 5,\n",
              " 'cost': 'l2',\n",
              " 'n_iter': 500,\n",
              " 'scaling': 0.99,\n",
              " 'lr': 0.001,\n",
              " 'use_bn': False,\n",
              " 'hidden_neurons': 256,\n",
              " 'hidden_layers': 2,\n",
              " 'activation': 'tanh',\n",
              " 'input_scale': [2, 2],\n",
              " 'input_mean': [-1, -1],\n",
              " 'input_dist': 'uniform',\n",
              " 'load_path': None}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = create_training_params_from_dict(d)\n",
        "print('training with parameters', params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OklcqBO2Zr7g",
        "outputId": "c865766c-3fb8-4c67-ba22-964aec3dc773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training with parameters Opt(exp_id=8973876331863215, shape_name='ellipsis', N=400000, eps=5, cost='l2', n_iter=500, scaling=0.99, lr=0.001, use_bn=False, hidden_neurons=256, hidden_layers=2, activation='tanh', input_scale=[2.0, 2.0], input_mean=[-1.0, -1.0], input_dist='uniform', load_path=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "shape_fn = make_shape_fn(params.shape_name)\n",
        "\n",
        "loss_args = {\n",
        "    'loss': \"sinkhorn\",\n",
        "    'cost': (l1_dist_formula, l1_dist) if params.cost == 'l1' else None,\n",
        "    'p': 2 if params.cost == 'l2' else 1,\n",
        "    'scaling': params.scaling,\n",
        "    'debias': False,\n",
        "    'backend': 'multiscale'\n",
        "}\n",
        "\n",
        "model_name = f'{params.shape_name}_{params.N}_{params.exp_id}_gen'\n",
        "a = (torch.ones(params.N)/params.N).to(device).double()\n",
        "b = (torch.ones(params.N)/params.N).to(device).double()\n",
        "print(f'Shape: {params.shape_name}')\n",
        "\n",
        "vals, sensitivity = shape_fn()\n",
        "sigma = get_sigma(eps=params.eps, delta=1e-4, sensitivity=2 * np.sqrt(2))  if params.cost == 'l2' else 4/params.eps\n",
        "loss = geomloss.SamplesLoss(**loss_args, blur=sigma if not use_emd else 1e-9)\n",
        "loss_potentials = geomloss.SamplesLoss(**loss_args, blur=sigma, potentials=True)\n",
        "\n",
        "if use_emd:\n",
        "  def loss(X, Y):\n",
        "    split_size = 1000\n",
        "    means = []\n",
        "    i = 0\n",
        "    for x, y in tqdm(\n",
        "        zip(torch.split(X, split_size), torch.split(Y, split_size)),\n",
        "        total=np.ceil(X.shape[0] / split_size).astype(int)):\n",
        "      i+= 1\n",
        "      C = cost_mat(x,y,params.cost)\n",
        "      pi =  ot.lp.emd(torch.ones(C.shape[0]).to(C.device)/C.shape[0],\n",
        "                                    torch.ones(C.shape[1]).to(C.device)/C.shape[1],\n",
        "                                    C, numThreads=10, numItermax=400)\n",
        "      cond_mean = torch.matmul(pi.float(), y.float())\n",
        "      means.append(cond_mean)\n",
        "    full_mean = torch.concatenate(means, dim = 0).detach()\n",
        "    return torch.square(full_mean - X).sum(-1).mean()\n",
        "  def loss_potentials(X, Y):\n",
        "    C = cost_mat(X,Y,params.cost)\n",
        "    l, d = ot.lp.emd2(torch.ones(C.shape[0]).to(C.device)/C.shape[0],\n",
        "                                  torch.ones(C.shape[1]).to(C.device)/C.shape[1],\n",
        "                                  C, log=True)\n",
        "    return d['u'], d['v']\n",
        "\n",
        "#input to generator sampler\n",
        "input_scale = np.array(params.input_scale)[None,:]\n",
        "input_mean = np.array(params.input_mean)[None,:]\n",
        "if params.input_dist == 'uniform':\n",
        "    input_generator_fn = lambda n: (torch.rand(n,2)*input_scale+input_mean).double().to(device)\n",
        "elif params.input_dist == 'normal':\n",
        "    input_generator_fn = lambda n: (torch.randn(n,2)*input_scale+input_mean).double().to(device)\n",
        "\n",
        "# generator & its optimizer\n",
        "torch.manual_seed(0);\n",
        "np.random.seed(0);\n",
        "G_input_val = input_generator_fn(params.N)\n",
        "G = Generator(\n",
        "    use_bn=params.use_bn, hidden_neurons=params.hidden_neurons, hidden_layers=params.hidden_layers,\n",
        "    activation=params.activation).to(device).double()\n",
        "\n",
        "optimizer_g = torch.optim.RMSprop(G.parameters(), lr=params.lr)\n",
        "G_input = input_generator_fn(params.N)\n",
        "\n",
        "\n",
        "# data & its privatized version\n",
        "sampled_idxs = np.random.choice(vals.shape[0], params.N if params.N!='all_random' else 10000)\n",
        "Xt = vals[sampled_idxs]\n",
        "Xt += np.random.normal(size=Xt.shape)*sigma if params.cost == 'l2' \\\n",
        "    else np.random.laplace(size=Xt.shape)*sigma\n",
        "xt = torch.tensor(Xt).to(device).double()\n",
        "\n",
        "# calculate the loss between privatized data and true data as baseline\n",
        "if params.load_path is not None:\n",
        "    with open(params.load_path, 'rb') as f:\n",
        "        d = pkl.load(f)\n",
        "    Xt = d['privatized']\n",
        "    vals = d['target']\n",
        "    G.load_state_dict(d['generator_state'])\n",
        "    optimizer_g.load_state_dict(d['optimizer_state'])\n",
        "    for p in optimizer_g.param_groups:\n",
        "        p['lr'] = params.lr\n",
        "\n",
        "    losses_gen = d['loss']\n",
        "    print('Loading model with params ', d['params'])\n",
        "else:\n",
        "    losses_gen = []\n",
        "print(\"The loss between samples without noise and the privatized ones:\",\n",
        "      float(loss(torch.Tensor(vals[sampled_idxs]).to(device).double(),\n",
        "                 xt.view(xt.shape[0], -1))))\n",
        "losses_tv = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGSdYF9dsZfO",
        "outputId": "6af08715-68ba-43b4-9113-97b0e112b583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: ellipsis\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:30<00:00, 13.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss between samples without noise and the privatized ones: 0.2721991197714133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the generator\n",
        "for i in range(params.n_iter):\n",
        "    gen_samples = G(G_input)\n",
        "    if use_emd:\n",
        "      gen_samples = G(G_input)\n",
        "      start_time = time.time()\n",
        "      loss_gen = loss(gen_samples, xt)\n",
        "      end_time = time.time()\n",
        "      start_time1 = time.time()\n",
        "      loss_gen.backward()\n",
        "      optimizer_g.step()\n",
        "      optimizer_g.zero_grad()\n",
        "      end_time1 = time.time()\n",
        "      loss_gen0 = 0\n",
        "      loss_diff = float(loss_gen.detach().cpu().numpy())\n",
        "    else:\n",
        "      start_time = time.time()\n",
        "      pot1, pot2 = loss_potentials(gen_samples, xt)\n",
        "      end_time = time.time()\n",
        "\n",
        "      start_time1 = time.time()\n",
        "\n",
        "      loss_gen0 = (pot1.mean() + pot2.mean()).detach()\n",
        "\n",
        "      if params.cost == 'l2':\n",
        "          cond_mean = transfer(\n",
        "                torch.Tensor([sigma**2]).type(torch.float64).to(device),\n",
        "                gen_samples.detach(),\n",
        "                xt,\n",
        "                pot1.detach().view(-1, 1),\n",
        "                pot2.detach().view(-1, 1),\n",
        "                xt\n",
        "                )/ params.N\n",
        "          loss_gen0 -= (torch.square(gen_samples).sum(-1).mean() - \\\n",
        "                        2*(gen_samples*cond_mean).sum(-1).mean() + \\\n",
        "                        torch.square(cond_mean).sum(-1).mean()).detach()\n",
        "      else:\n",
        "        gen_samples_old = gen_samples\n",
        "        diff_pi_fn = lambda gen_new: (loss_l1(\n",
        "              torch.Tensor([sigma]).type(torch.float64).to(device),\n",
        "              gen_samples_old.detach(),\n",
        "              xt,\n",
        "              pot1.detach().view(-1, 1),\n",
        "              pot2.detach().view(-1, 1),\n",
        "              gen_new\n",
        "              )/ params.N).mean()\n",
        "        loss_gen0 -= diff_pi_fn(gen_samples.detach()).detach()\n",
        "\n",
        "      loss_gen0 = float(loss_gen0.cpu().numpy())\n",
        "      loss_gen = np.inf\n",
        "      n_iter_G = 0\n",
        "      # while loss_gen > 1e-4 and n_iter_G < max_iter_G:\n",
        "      if True:\n",
        "        n_iter_G += 1\n",
        "        gen_samples = G(G_input)\n",
        "        if params.cost == 'l2':\n",
        "          loss_gen = torch.square(gen_samples).sum(-1).mean() - 2*(gen_samples*cond_mean).sum(-1).mean() + torch.square(cond_mean).sum(-1).mean()\n",
        "        else:\n",
        "          loss_gen = diff_pi_fn(gen_samples)\n",
        "        loss_gen.backward()\n",
        "        optimizer_g.step()\n",
        "        optimizer_g.zero_grad()\n",
        "        # print(loss_gen)\n",
        "      end_time1 = time.time()\n",
        "      loss_diff = float(loss_gen.detach().cpu().numpy())\n",
        "    tv = get_tv(vals, gen_samples.detach().cpu().numpy())\n",
        "    # print('generator iterations', n_iter_G, 'loss difference: ', loss_diff)\n",
        "    losses_gen.append(loss_diff + loss_gen0)\n",
        "    losses_tv.append(tv)\n",
        "    print(params.shape_name, 'iter', i+1, 'loss: ', losses_gen[-1],\n",
        "          'loss calc time: ', end_time-start_time,\n",
        "          'backward pass time: ', end_time1-start_time1,\n",
        "          'TV: ', tv)\n",
        "\n",
        "    if (i+1) % 10 == 0:\n",
        "        with open(f'{project_path}/generated_samples/{model_name}.pkl', 'wb') as f:\n",
        "            pkl.dump({\n",
        "                'privatized': Xt,\n",
        "                'target': vals,\n",
        "                'generator_state': G.state_dict(),\n",
        "                'optimizer_state': optimizer_g.state_dict(),\n",
        "                'loss': losses_gen,\n",
        "                'loss_tv': losses_tv,\n",
        "                'params': params,\n",
        "            }, f)\n",
        "        new_gen_samples = G(G_input_val).cpu().detach().numpy()\n",
        "        plt.figure(figsize = (5,5))\n",
        "        plt.scatter(*Xt.T, label = 'privatized', s=1, alpha = .3)\n",
        "        plt.scatter(*vals.T, label = 'target', s = 10, c='k')\n",
        "        plt.scatter(*(new_gen_samples.T), label='generated', s=1, alpha = .1, c='y')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.xlim(-3, 3)\n",
        "        plt.ylim(-3, 3)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.savefig(f'{project_path}/imgs/{model_name}.png')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        plt.figure(figsize = (5,5))\n",
        "        plt.scatter(*Xt.T, label = 'privatized', s=1, alpha = .3)\n",
        "        plt.scatter(*vals.T, label = 'target', s = 10, c='k')\n",
        "        plt.scatter(*(new_gen_samples.T), label='generated', s=1, alpha = .013, c='y')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.xlim(-10, 10)\n",
        "        plt.ylim(-10, 10)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.savefig(f'{project_path}/imgs/{model_name}_enlarged.png')\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "efc9weAEZpTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_gen_samples = G(G_input).cpu().detach().numpy()\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.scatter(*Xt.T, label = 'privatized', s=1, alpha = .3)\n",
        "plt.scatter(*vals.T, label = 'target', s = 10, c='k')\n",
        "plt.scatter(*(new_gen_samples.T), label='generated', s=1, alpha = .1, c='y')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(-3, 3)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.savefig(f'{project_path}/imgs/{model_name}.png')\n",
        "plt.close()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O3C_RX6LfElA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}